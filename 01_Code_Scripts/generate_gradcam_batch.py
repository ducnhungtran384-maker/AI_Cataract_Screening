import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image
import numpy as np
import matplotlib
matplotlib.use('Agg')  # éäº¤äº’å¼åç«¯
import matplotlib.pyplot as plt
import cv2
import os
import json
import re
from tqdm import tqdm

# ==========================================
# Grad-CAM æ‰¹é‡ç”Ÿæˆè„šæœ¬
# ä¸ºæ‰€æœ‰é”™è¯¯æ¡ˆä¾‹ç”Ÿæˆçƒ­åŠ›å›¾
# ==========================================

# é…ç½®
MODEL_PATH = "../result/best_cataract_model.pth"
ERROR_DATA_JS = "../visualization/js/error_data.js"
ERROR_IMAGES_DIR = "../visualization/error_images"
OUTPUT_DIR = "../visualization/gradcam_heatmaps"

class GradCAM:
    def __init__(self, model, target_layer):
        self.model = model
        self.target_layer = target_layer
        self.gradients = None
        self.activations = None
        
        self.target_layer.register_forward_hook(self.save_activation)
        self.target_layer.register_full_backward_hook(self.save_gradient)

    def save_activation(self, module, input, output):
        self.activations = output

    def save_gradient(self, module, grad_input, grad_output):
        self.gradients = grad_output[0]

    def generate_heatmap(self, input_tensor, class_idx=None):
        output = self.model(input_tensor)
        if class_idx is None:
            class_idx = torch.argmax(output)
        
        self.model.zero_grad()
        output[0, class_idx].backward()
        
        weights = torch.mean(self.gradients, dim=(2, 3), keepdim=True)
        cam = torch.sum(weights * self.activations, dim=1).squeeze()
        
        cam = np.maximum(cam.detach().cpu().numpy(), 0)
        if cam.max() != 0:
            cam = cam / cam.max()
            
        return cam, class_idx.item()

def parse_error_cases(error_data_js):
    """ä» error_data.js ä¸­è§£æé”™è¯¯æ¡ˆä¾‹"""
    with open(error_data_js, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æå– filename
    filenames = re.findall(r'"filename":\s*"([^"]+)"', content)
    return filenames

def generate_gradcam_batch():
    print("="*60)
    print("Grad-CAM æ‰¹é‡ç”Ÿæˆè„šæœ¬")
    print("="*60)
    
    # 1. åˆ›å»ºè¾“å‡ºç›®å½•
    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)
        print(f"âœ… åˆ›å»ºè¾“å‡ºç›®å½•: {OUTPUT_DIR}")
    
    # 2. åŠ è½½æ¨¡å‹
    print("\nğŸ“¦ åŠ è½½æ¨¡å‹...")
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = models.resnet18(weights=None)
    model.fc = nn.Linear(model.fc.in_features, 2)
    
    try:
        model.load_state_dict(torch.load(MODEL_PATH, map_location=device))
        model = model.to(device).eval()
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ (è®¾å¤‡: {device})")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return
    
    # 3. è§£æé”™è¯¯æ¡ˆä¾‹
    print("\nğŸ“‹ è§£æé”™è¯¯æ¡ˆä¾‹åˆ—è¡¨...")
    error_files = parse_error_cases(ERROR_DATA_JS)
    print(f"âœ… æ‰¾åˆ° {len(error_files)} ä¸ªé”™è¯¯æ¡ˆä¾‹")
    
    # 4. å‡†å¤‡ Grad-CAM
    target_layer = model.layer4[-1]
    cam_engine = GradCAM(model, target_layer)
    
    # 5. é¢„å¤„ç†
    preprocess = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    
    # 6. æ‰¹é‡ç”Ÿæˆ
    print("\nğŸ”¥ å¼€å§‹ç”Ÿæˆ Grad-CAM çƒ­åŠ›å›¾...\n")
    successful = []
    failed = []
    
    for filename in tqdm(error_files, desc="ç”Ÿæˆè¿›åº¦"):
        try:
            # è¯»å–å›¾ç‰‡
            img_path = os.path.join(ERROR_IMAGES_DIR, filename)
            if not os.path.exists(img_path):
                failed.append((filename, "æ–‡ä»¶ä¸å­˜åœ¨"))
                continue
            
            img = Image.open(img_path).convert('RGB')
            input_tensor = preprocess(img).unsqueeze(0).to(device)
            
            # ç”Ÿæˆçƒ­åŠ›å›¾
            heatmap, pred_idx = cam_engine.generate_heatmap(input_tensor)
            
            # è°ƒæ•´å¤§å°å¹¶ä¸Šè‰²
            heatmap_resized = cv2.resize(heatmap, (img.size[0], img.size[1]))
            heatmap_colored = cv2.applyColorMap(np.uint8(255 * heatmap_resized), cv2.COLORMAP_JET)
            heatmap_colored = cv2.cvtColor(heatmap_colored, cv2.COLOR_BGR2RGB)
            
            # å åŠ 
            overlayed = np.float32(heatmap_colored) * 0.4 + np.float32(np.array(img)) * 0.6
            overlayed = np.uint8(overlayed)
            
            # åˆ›å»ºä¸‰å›¾å¯¹æ¯”
            fig, axes = plt.subplots(1, 3, figsize=(15, 5))
            
            axes[0].imshow(img)
            axes[0].set_title('Original Image', fontsize=12)
            axes[0].axis('off')
            
            axes[1].imshow(heatmap_resized, cmap='jet')
            axes[1].set_title('AI Focus Heatmap', fontsize=12)
            axes[1].axis('off')
            
            axes[2].imshow(overlayed)
            classes = ['Cataract', 'Normal']
            axes[2].set_title(f'Prediction: {classes[pred_idx]}', fontsize=12)
            axes[2].axis('off')
            
            plt.tight_layout()
            
            # ä¿å­˜
            output_filename = os.path.splitext(filename)[0] + '_gradcam.png'
            output_path = os.path.join(OUTPUT_DIR, output_filename)
            plt.savefig(output_path, dpi=100, bbox_inches='tight')
            plt.close()
            
            successful.append(filename)
            
        except Exception as e:
            failed.append((filename, str(e)))
    
    # 7. ç»Ÿè®¡æŠ¥å‘Š
    print("\n" + "="*60)
    print("ğŸ“Š ç”Ÿæˆå®Œæˆç»Ÿè®¡")
    print("="*60)
    print(f"âœ… æˆåŠŸ: {len(successful)} å¼ ")
    print(f"âŒ å¤±è´¥: {len(failed)} å¼ ")
    
    if failed:
        print("\nå¤±è´¥åˆ—è¡¨:")
        for fname, reason in failed:
            print(f"  - {fname}: {reason}")
    
    print(f"\nğŸ’¾ çƒ­åŠ›å›¾å·²ä¿å­˜è‡³: {OUTPUT_DIR}")
    print("="*60)
    
    return successful, failed

if __name__ == "__main__":
    generate_gradcam_batch()
