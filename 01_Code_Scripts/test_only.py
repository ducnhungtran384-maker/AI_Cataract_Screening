# çº¯æµ‹è¯•è„šæœ¬ï¼šåªè¾“å‡ºç»“æœï¼Œä¸ä¿®æ”¹ä»»ä½•æ–‡ä»¶
import torch
import torch.nn as nn
from torchvision import datasets, models, transforms
from torch.utils.data import DataLoader
import numpy as np
from sklearn.metrics import confusion_matrix

# ================= é…ç½®åŒº =================
MODEL_PATH = "../result/best_cataract_model.pth"
DATA_PATH = "../04data/ALL_Data_split12/Test"
# ==========================================

def test_model():
    print("=" * 60)
    print("ğŸ”¬ PyTorch æ¨¡å‹æµ‹è¯• (ä»…è¾“å‡ºç»“æœï¼Œä¸ä¿®æ”¹ä»»ä½•æ–‡ä»¶)")
    print("=" * 60)
    
    # è®¾å¤‡
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    print(f"è®¾å¤‡: {device}")
    
    # æ•°æ®é¢„å¤„ç†
    data_transforms = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    
    # åŠ è½½æ•°æ®é›†
    dataset = datasets.ImageFolder(DATA_PATH, transform=data_transforms)
    dataloader = DataLoader(dataset, batch_size=32, shuffle=False)
    print(f"æµ‹è¯•é›†è·¯å¾„: {DATA_PATH}")
    print(f"æµ‹è¯•é›†å¤§å°: {len(dataset)} å¼ å›¾ç‰‡")
    print(f"ç±»åˆ«æ˜ å°„: {dataset.class_to_idx}")
    
    # åŠ è½½æ¨¡å‹ (ResNet18)
    print("\næ­£åœ¨åŠ è½½æ¨¡å‹...")
    model = models.resnet18(weights=None)
    model.fc = nn.Linear(model.fc.in_features, 2)
    model.load_state_dict(torch.load(MODEL_PATH, map_location=device))
    model = model.to(device)
    model.eval()
    print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!")
    
    # æ¨ç†
    print("\næ­£åœ¨è¿›è¡Œæ¨ç†...")
    all_preds = []
    all_labels = []
    all_confs = []
    
    with torch.no_grad():
        for inputs, labels in dataloader:
            inputs = inputs.to(device)
            outputs = model(inputs)
            probs = torch.softmax(outputs, dim=1)
            confs, preds = torch.max(probs, 1)
            
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
            all_confs.extend(confs.cpu().numpy())
    
    # è½¬ä¸º numpy
    all_preds = np.array(all_preds)
    all_labels = np.array(all_labels)
    all_confs = np.array(all_confs)
    
    # è®¡ç®—æ··æ·†çŸ©é˜µ
    # class 0: Cataract, class 1: Normal (ImageFolder æŒ‰å­—æ¯åº)
    cm = confusion_matrix(all_labels, all_preds)
    tp = cm[0, 0]  # Cataract é¢„æµ‹ä¸º Cataract
    fn = cm[0, 1]  # Cataract é¢„æµ‹ä¸º Normal (æ¼è¯Š)
    fp = cm[1, 0]  # Normal é¢„æµ‹ä¸º Cataract (è¯¯è¯Š)
    tn = cm[1, 1]  # Normal é¢„æµ‹ä¸º Normal
    
    # è®¡ç®—æŒ‡æ ‡
    total = len(all_labels)
    accuracy = (tp + tn) / total
    precision = tp / (tp + fp) if (tp + fp) > 0 else 0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0  # æ•æ„Ÿåº¦
    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0
    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
    
    # è¾“å‡ºç»“æœ
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•ç»“æœ")
    print("=" * 60)
    
    print(f"\nã€æ··æ·†çŸ©é˜µã€‘")
    print(f"              é¢„æµ‹Cataract  é¢„æµ‹Normal")
    print(f"å®é™…Cataract     {tp:5d}        {fn:5d}")
    print(f"å®é™…Normal       {fp:5d}        {tn:5d}")
    
    print(f"\nã€å…³é”®æŒ‡æ ‡ã€‘")
    print(f"  å‡†ç¡®ç‡ (Accuracy):    {accuracy:.2%} ({tp+tn}/{total})")
    print(f"  ç²¾ç¡®ç‡ (Precision):   {precision:.2%}")
    print(f"  å¬å›ç‡ (Recall):      {recall:.2%} (æ•æ„Ÿåº¦/æ¼è¯Šç‡çš„å¯¹ç«‹é¢)")
    print(f"  ç‰¹å¼‚åº¦ (Specificity): {specificity:.2%} (è¯¯è¯Šç‡çš„å¯¹ç«‹é¢)")
    print(f"  F1 Score:             {f1:.4f}")
    print(f"  å¹³å‡ç½®ä¿¡åº¦:           {np.mean(all_confs):.2%}")
    
    print(f"\nã€åˆ†ç±»è¯¦æƒ…ã€‘")
    cataract_count = np.sum(all_labels == 0)
    normal_count = np.sum(all_labels == 1)
    print(f"  Cataract: {tp}/{cataract_count} æ­£ç¡® ({tp/cataract_count:.2%})")
    print(f"  Normal:   {tn}/{normal_count} æ­£ç¡® ({tn/normal_count:.2%})")
    
    print(f"\nã€ç½®ä¿¡åº¦åˆ†å¸ƒã€‘")
    bins = [0, 0.6, 0.7, 0.8, 0.9, 0.95, 1.0]
    hist, _ = np.histogram(all_confs, bins=bins)
    print(f"  <60%:     {hist[0]}")
    print(f"  60%-70%:  {hist[1]}")
    print(f"  70%-80%:  {hist[2]}")
    print(f"  80%-90%:  {hist[3]}")
    print(f"  90%-95%:  {hist[4]}")
    print(f"  >95%:     {hist[5]}")
    
    # JSON æ ¼å¼è¾“å‡º (æ–¹ä¾¿åç»­ä½¿ç”¨)
    print(f"\nã€JSON æ ¼å¼ (ä¾›åç»­é›†æˆç”¨)ã€‘")
    import json
    result = {
        "overall": {
            "accuracy": round(accuracy, 4),
            "precision": round(precision, 4),
            "recall": round(recall, 4),
            "f1": round(f1, 4),
            "specificity": round(specificity, 4),
            "confusion_matrix": {"TP": int(tp), "TN": int(tn), "FP": int(fp), "FN": int(fn)},
            "avg_confidence": round(float(np.mean(all_confs)), 4),
            "total": int(total),
            "confidence_distribution": hist.tolist()
        },
        "cataract": {
            "precision": round(precision, 4),
            "recall": round(recall, 4),
            "count": int(cataract_count),
            "correct": int(tp),
            "avg_confidence": round(float(np.mean(all_confs[all_labels == 0])), 4)
        },
        "normal": {
            "precision": round(tn/(tn+fn) if (tn+fn)>0 else 0, 4),
            "recall": round(specificity, 4),
            "count": int(normal_count),
            "correct": int(tn),
            "avg_confidence": round(float(np.mean(all_confs[all_labels == 1])), 4)
        }
    }
    print(json.dumps(result, indent=2, ensure_ascii=False))
    
    print("\n" + "=" * 60)
    print("âœ… æµ‹è¯•å®Œæˆ! ä»¥ä¸Šæ•°æ®æœªå†™å…¥ä»»ä½•æ–‡ä»¶")
    print("=" * 60)

if __name__ == "__main__":
    test_model()
